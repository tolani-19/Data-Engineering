{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0b1a5959-9fe6-44d7-a36a-94c0e3398431",
   "metadata": {},
   "source": [
    "## Building Data Pipelines in Airflow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb504a47-c2e5-488e-ad85-1e201208c85d",
   "metadata": {},
   "source": [
    "Every DAG is going to have some standard, boilerplate code to make it run in Airflow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec5eb5b9-b192-49af-9752-5deab7faaa97",
   "metadata": {},
   "source": [
    "You will always import the needed libraries, and then any other libraries you need for your\n",
    "tasks. In the following code block, you import the operator, DAG, and the time libraries\n",
    "for Airflow. For your tasks, you import the pandas, psycopg2, and elasticsearch\n",
    "libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "58e117da-16df-4b37-87a0-fd5fdb077aba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "37a7d27f-2f0e-4f20-be26-d3c4a7c18896",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\u001b[34m2022-08-15 11:14:10,080\u001b[0m] {\u001b[34mutils.py:\u001b[0m159} INFO\u001b[0m - NumExpr defaulting to 4 threads.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import datetime as dt\n",
    "from datetime import timedelta\n",
    "from airflow import DAG\n",
    "from airflow.operators.bash import BashOperator\n",
    "from airflow.operators.python import PythonOperator\n",
    "import pandas as pd\n",
    "import psycopg2 as db\n",
    "from elasticsearch import Elasticsearch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "699067ca-9743-4502-af5c-5c56e662637b",
   "metadata": {},
   "source": [
    "To query PostgreSQL, you create the connection, execute the sql query using the\n",
    "pandas read_sql() method, and then use the pandas to_csv() method to write\n",
    "the data to disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "42590c2f-f57d-4d30-8388-58f44e95b98a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a connection string that contains the host, database, username and password\n",
    "conn_string=\"dbname='Data Engineering' user='postgres' password='KARima@2019?'\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1e5c800b-64d9-43f4-842a-38ea63e7562e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create the connection object by passing the connection string to the connect()method\n",
    "conn=db.connect(conn_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "de3d6e9e-ae9b-4bee-b564-7677126cffcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create the cursor from the connection\n",
    "cur=conn.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "083b99d2-768e-4ea9-9fe5-3fb887150c63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------Data Saved------\n"
     ]
    }
   ],
   "source": [
    "def queryPostgresql():\n",
    "    conn_string=\"dbname='Data Engineering' user='postgres' password='KARima@2019?'\"\n",
    "    conn=db.connect(conn_string)\n",
    "    cur=conn.cursor()\n",
    "df=pd.read_sql(\"select name,city from task1\",conn)\n",
    "df.to_csv('postgresqldata.csv')\n",
    "print(\"-------Data Saved------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69751721-e200-4086-95c9-e5cd76e94c19",
   "metadata": {},
   "source": [
    "To insert the data into Elasticsearch, you create the Elasticsearch object connecting\n",
    "to localhost. Then, read the CSV from the previous task into a DataFrame, iterate\n",
    "through the DataFrame, converting each row into JSON, and insert the data using the\n",
    "index method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "665fa382-6035-45ac-85c1-ecbcb84f954e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a connection to elastic search and type your password\n",
    "es=Elasticsearch('https://localhost:9200', verify_certs=False, basic_auth=('elastic', '5_AQGZ0kKSiqSI_fhaPF'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c00da200-b75b-4c13-a3d6-6e65f68e8a20",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>name</th>\n",
       "      <th>city</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Big Bird</td>\n",
       "      <td>Fakeville</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Brittany Mendoza</td>\n",
       "      <td>Nicolechester</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Brenda Bowen</td>\n",
       "      <td>Catherineton</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Keith Yang</td>\n",
       "      <td>Bridgetburgh</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Timothy Mccormick</td>\n",
       "      <td>Tuckerside</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>996</td>\n",
       "      <td>Nancy Ramsey</td>\n",
       "      <td>Ryanburgh</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>997</td>\n",
       "      <td>James Jenkins</td>\n",
       "      <td>Paulaport</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>998</td>\n",
       "      <td>Sarah Herrera</td>\n",
       "      <td>Annshire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>999</td>\n",
       "      <td>Theresa Mcbride</td>\n",
       "      <td>West Andreburgh</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000</th>\n",
       "      <td>1000</td>\n",
       "      <td>Donna Gomez</td>\n",
       "      <td>South Heather</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1001 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0               name             city\n",
       "0              0           Big Bird        Fakeville\n",
       "1              1   Brittany Mendoza    Nicolechester\n",
       "2              2       Brenda Bowen     Catherineton\n",
       "3              3         Keith Yang     Bridgetburgh\n",
       "4              4  Timothy Mccormick       Tuckerside\n",
       "...          ...                ...              ...\n",
       "996          996       Nancy Ramsey        Ryanburgh\n",
       "997          997      James Jenkins        Paulaport\n",
       "998          998      Sarah Herrera         Annshire\n",
       "999          999    Theresa Mcbride  West Andreburgh\n",
       "1000        1000        Donna Gomez    South Heather\n",
       "\n",
       "[1001 rows x 3 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def insertElasticsearch():\n",
    "    es = Elasticsearch('https://localhost:9200', verify_certs=False, basic_auth=('elastic', '5_AQGZ0kKSiqSI_fhaPF'))\n",
    "df=pd.read_csv(\"postgresqldata.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "77044f71-5e65-41d0-be00-e2fda555a36c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\u001b[34m2022-08-15 11:14:20,764\u001b[0m] {\u001b[34m_transport.py:\u001b[0m336} INFO\u001b[0m - POST https://localhost:9200/frompostgresql/_doc [status:201 duration:0.803s]\u001b[0m\n",
      "{'_index': 'frompostgresql', '_id': '133_oIIBM6TF6_YKRlrW', '_version': 1, 'result': 'created', '_shards': {'total': 2, 'successful': 1, 'failed': 0}, '_seq_no': 0, '_primary_term': 1}\n"
     ]
    }
   ],
   "source": [
    "for i, r in df.iterrows():\n",
    "    doc=r.to_json()\n",
    "res=es.index(index=\"frompostgresql\", body=doc)\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99aa3363-b851-40af-b822-19ef03fc99c0",
   "metadata": {},
   "source": [
    "Next, you will specify the arguments for your DAG. Remember that the start time should\n",
    "be a day behind if you schedule the task to run daily"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "89104364-c63c-4edb-b628-f6c0c1763137",
   "metadata": {},
   "outputs": [],
   "source": [
    "default_args = {\n",
    " 'owner': 'tolani',\n",
    " 'start_date': dt.datetime(2022, 9, 14),\n",
    " 'retries': 1,\n",
    " 'retry_delay': dt.timedelta(minutes=5),\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "671d9920-a21f-4491-a608-04f6e1839c39",
   "metadata": {},
   "source": [
    "Now, you can pass the arguments to the DAG, name it, and set the run interval. You will\n",
    "define your operators here as well. In this example, you will create two Python operators –\n",
    "one to get data from PostgreSQL and one to insert data in to Elasticsearch. The getData\n",
    "task will be upstream and the insertData task downstream, so you will use the >> bit\n",
    "shift operator to specify this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e32bb752-158f-4e38-9878-ae5f21c12b1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Task(PythonOperator): InsertDataElasticsearch>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with DAG('MyDBdag',\n",
    " default_args=default_args,\n",
    " schedule_interval=timedelta(minutes=5),\n",
    " # '0 * * * *',\n",
    " ) as dag:\n",
    "    print_starting = BashOperator(task_id=\"starting\" ,bash_command='echo \"I am reading the PostgreSQL now.....\"')\n",
    "    getData = PythonOperator(task_id='QueryPostgreSQL',python_callable=queryPostgresql)\n",
    "    insertData = PythonOperator(task_id='InsertDataElasticsearch',python_callable=insertElasticsearch)\n",
    "print_starting >> getData >> insertData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0df069d8-7dee-486f-ab8e-67bdb3354487",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
